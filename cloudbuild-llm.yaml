# Build & deploy LLM (llm-service/) to Cloud Run with a GCS mount
# Place at repo root. Trigger on changes to llm-service/**

substitutions:
  _REGION: europe-west1
  _SERVICE: llama-cpu
  _REPO: llm-repo
  _IMAGE: llama-cpu
  _BUCKET: gs://my_models         # underscore is OK for mounting
  _MOUNT_PATH: /models            # visible path inside the container
  _SA: llm-model-reader@fluted-haven-467020-v1.iam.gserviceaccount.com

steps:
  - name: "gcr.io/cloud-builders/docker"
    dir: "llm-service"
    args: ["build", "-t", "${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/${_IMAGE}:$SHORT_SHA", "."]

  - name: "gcr.io/cloud-builders/docker"
    args: ["push", "${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/${_IMAGE}:$SHORT_SHA"]

  - name: "gcr.io/google.com/cloudsdktool/cloud-sdk"
    entrypoint: gcloud
    args:
      [
        "run","deploy","${_SERVICE}",
        "--image","${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/${_IMAGE}:$SHORT_SHA",
        "--region","${_REGION}",
        "--cpu","2",
        "--memory","8Gi",
        "--timeout","900",
        "--service-account","${_SA}",
        "--ingress","internal-and-cloud-load-balancing",
        "--no-allow-unauthenticated",
        "--min-instances","1",
        "--set-env-vars","MODEL_DIR=${_MOUNT_PATH}",
        "--mount","type=gcs,src=${_BUCKET},target=${_MOUNT_PATH},readonly=true",
        "--project","$PROJECT_ID"
      ]

images:
  - "${_REGION}-docker.pkg.dev/$PROJECT_ID/${_REPO}/${_IMAGE}:$SHORT_SHA"
